[{"url":"/docs/change-log/version","title":"Version","description":"Learn about the change log of the JMS Bridge","section":"Change Log","body":"\nIn this section we will provide the following information for each release:\n\n- A link to the full release notes which includes all issues resolved in the release.\n- A brief list of \"highlights\" when applicable.\n- If necessary, specific steps required when upgrading from the previous version.\n  - Note: If the upgrade spans multiple versions then the steps from each version need to be followed in order.\n  - Note: Follow the general upgrade procedure outlined in the Upgrading the Broker chapter in addition to any version-specific upgrade instructions outlined here.\n\n## v. 1.0\n\n### Release Notes\n\n#### Feature Changelog\n\n| Feature                     | Description                                                              | Jira                                                           |\n| --------------------------- | ------------------------------------------------------------------------ | -------------------------------------------------------------- |\n| JMS-Bridge HA               | Active/Standby HA support for the JMS Bridge                             | [CSID-337](https://confluentinc.atlassian.net/browse/CSID-337) |\n| JMS-Bridge Storage in Kafka | All JMS-Bridge journal data stored in Kafka                              | [CSID-242](https://confluentinc.atlassian.net/browse/CSID-242) |\n| Documentation Improvements  | Add documentation about collecting telemetry, identify missing telemetry | [CSID-338](https://confluentinc.atlassian.net/browse/CSID-338) |\n\n#### Caveats\n\n| Feature            | Caveats                                                                                                                                |\n| ------------------ | -------------------------------------------------------------------------------------------------------------------------------------- |\n| JMS-Bridge HA      | Shared Storage, JDBC, and VM HA methods found in ActiveMQ Artemis will no longer be available nor relevant for the JMS-Bridge Project. |\n| JMS-Bridge Storage | Alternative storage schema like JdBC, and shared disk, are no longer applicable in the broker.xml configurations.                      |\n| JMS-Bridge Storage | rge Message Support has been depricated.                                                                                               |\n"},{"url":"/docs/get-started/architecture","title":"Architecture","description":"Learn about the architecture of the JMS Bridge","section":"Get Started","body":"\nThis is an overview of how different features within the JMS-Bridge were implemented.\n\n## Message Integration to Kafka\n\nA major component of the JMS Bridge is to allow interoperability between JMS clients and Kafka clients.\nTo do this involves publishing JMS messages to Kafka so they are available to the clients there.\nSeveral aspects need to be considered when doing this.\n\n1. Conversion of JMS message types to Kafka messages\n1. Preservation of JMS message metadata\n1. Whether to propagate non-durable JMS messages\n1. Mapping of JMS topics to Kafka topics\n1. Extraction of Kafka message key from JMS messages\n\nAlso we must consider that JMS supports point-to-point queue semantics where as Kafka only supports the pub-sub model.\nAs a follow up we may want to integrate PTP semantics via a convention that can be used by kafka clients.\n\n1. Support for PTP semantics (request/reply)\n\n### Current JMS Bridge Integration\n\nTo integrate in this feature we will use the already existing kafka streams topology found in the JMS-Bridge.\nInstead of ignoring newly added messages those messages will be routed and published to kafka by extending the existing topology.\n\n```plaintext\n    kafka streams\n        from journal topic\n            |\n            V\n        process transactions\n            |\n            V\n        process deletes/annotations\n            |\n            |--> process adds\n            |       |  *** the message integration magic ***\n            |       |\n            |       V\n            |    route messages*\n            |       |\n            |       V\n            |    convert messages*\n            |       |\n            |       V\n            |    publish to topics*\n            V\n        publish updates to journal topic\n```\n\n### Routing Messages\n\nInitial implementation of routing will be simplistic and hands on.\nIt will require the JMS-Bridge to be configured with information about:\n\n- A route that contains\n  1. a message filter predicate that when true marks it as a part of this routing\n     - JMS address, JMS header value\n  1. a destination kafka topic that the message should be published to\n  1. a conversion mechanism informing how it should be converted\n     - Kafka key to extract from the message\n\n#### Assumptions\n\n1. The destination kafka topic has been created and exists\n1. The JMS-Bridge kafka principal has permission to publish to the topic\n1. The JMS messages are either binary or text\n\n#### Limitations\n\nA message may only be routed to a single kafka topic and it will be derived from the first route that matches.\nThe order of the routing will be maintained from how it is ordered in the configuration.\n\n### Converting Messages\n\nAll JMS headers will be converted to corresponding Kafka message headers using a standard convention.\nThe convention will be:\n\n```plaintext\njms.<jms_property_name>\n\n//e.g.\nMessageId -> jms.MessageId\n```\n\nA JMS Bridge origin header will also be added to aid in the prevention of data cycles.\n\n```properties\njmsbridge.origin=<bridge.id>\n```\n\nAs part of the conversion a key for the message will be selected for publishing to kafka.\nThe choice of this key is important since it determines how Kafka's ordering guarantees are enforced.\nInitially it can be configured to use any available JMS header with a text or numeric value as the key.\nIf no key is specified then the `MessageId` will be used.\n\nSince only text and binary messages will be propagated at this time the contents of those messages will be published as-is to kafka.\n\n### Configuring Routes\n\nRoutes will be configured in the jms-bridge.properties file.\nEach route will require a unique name, routing predicate, destination kafka topic and conversion options.\nThe configuration will be processed from the top down, any duplicate keys will override the preceding one.\n\n```properties\nrouting.dead-letter-topic=jms-bridge-to-kafka-dead-letter-topic\n\nroutes.fooRoute.name=fooRoute\nroutes.fooRoute.in.include=msg.address==foo-topic\nroutes.fooRoute.out.topic=foobar-topic\nroutes.fooRoute.conv.key=msg.header.CorrelationId\n\nroutes.barRoute.name=barRoute\nroutes.barRoute.in.include=msg.address==bar-topic\nroutes.barRoute.out.topic=foobar-topic\nroutes.barRoute.map.key=msg.header.CorrelationId\n```\n\n### Error Handling\n\nThere are two kinds of failures, hard failures and soft failures.\nHard failures are ones that cannot be recovered from and include:\n\n1. Invalid kafka topic destination\n1. Not authorized to write to the kafka topic\n\nThese will cause a hard stop of the jms-bridge.\n\nSoft failures on the other hand are usually data related.\nThese include:\n\n1. Key mapping invalid (no key found, key value isn't alphanumeric)\n1. Conversion failure (message type is not text/binary)\n\nThese can be configured to either cause a hard stop (default) or continue processing.\nOptions that allow for continued processing after encountering the error include:\n\n1. Log and Skip the message\n1. Log and dead letter the message\n\nDead lettered messages will be published to another kafka topic which can be later inspected.\nThe `routing.dead-letter.topic` can be used to configure which topic to publish to in Kafka.\nIf for some reason publishing to that topic fails then a hard stop will occur.\n\n### Telemetry\n\nTelemetry for the routing will be found within the kafka streams JMX beans.\nCustom metrics include:\n\n_`stream-jms-bridge-metrics[jms-bridge-id=router][routing-latency-avg]`_\n\nThis is the average time it takes to route and convert the record.\n\n_`stream-jms-bridge-metrics[jms-bridge-id=router][routing-success-rate]`_\n\nThe number of successful routings since the server started.\n\n_`stream-jms-bridge-metrics[jms-bridge-id=router][routing-failure-rate]`_\n\nThe number failed routings since the server started.\n"},{"url":"/docs/get-started/cli","title":"Command Line Interface","description":"Learn about the command line interface of the JMS Bridge","section":"Get Started","body":"\nThe JMS Bridge cli tool, `jms-bridge`, is available to perform some simple actions.\nCurrently it supports sending and receiving of JMS text messages across a topic.\n\nTo see all of the options use the included help system by executing `jms-bridge help`.\n"},{"url":"/docs/get-started/configuration","title":"Configuration","description":"Learn about the configuration of the JMS Bridge","section":"Get Started","body":"\nAll configuration for the JMS Bridge is done via a file which is supplied to the [jms-bridge-server-start](https://github.com/confluentinc/csid-jms-bridge/tree/master/bin/jms-bridge-server-start) script.\nAn example configuration can be found in [etc/jms-bridge.conf](https://github.com/confluentinc/csid-jms-bridge/tree/master/config/jms-bridge.conf).\n\nThe configuration is written using Lightbends config library and file format, HOCON (see <https://github.com/lightbend/config>).\nHOCON is fairly straight forward and is compatible with JSON and even java properties but it also has more advanced features which can simplify configuration.\nUse the default configuration as a reference when customizing it your own.\n\n## Artemis Configuration\n\nSince the underlying JMS engine is a customized embedded Apache ActiveMQ Artemis broker one can configure that directly.\nTo do so requires editing the [broker.xml](https://github.com/confluentinc/csid-jms-bridge/tree/master/config/broker.xml) file found in the [etc](https://github.com/confluentinc/csid-jms-bridge/tree/master/config) directory.\nThe [broker.xml](https://github.com/confluentinc/csid-jms-bridge/tree/master/config/broker.xml). file must be located next to the configured [etc/jms-bridge.properties](https://github.com/confluentinc/csid-jms-bridge/tree/master/config/jms-bridge.properties.template) file or it will not be found.\n\nA default [broker.xml](https://github.com/confluentinc/csid-jms-bridge/tree/master/config/broker.xml) is supplied with the installation.\nFeel free to update it as desired.\nThe reference for that file can be found on the Artemis documentation site:\n<https://activemq.apache.org/components/artemis/documentation/latest/configuration-index.html>\n\n## Configuration Reference\n\nSee the default configuration file [etc/jms-bridge.conf](https://github.com/confluentinc/csid-jms-bridge/tree/master/config/jms-bridge.conf) for information on all of the configuration options.\n"},{"url":"/docs/get-started/installation","title":"Installation","description":"Learn how to install the JMS Bridge","section":"Get Started","body":"\n## Prerequisites\n\n1. Unix based operating system\n1. Java JDK 1.8 or newer\n\n## Acquire Release Archive\n\nAt this time we do not have a place to download releases of the JMS-Bridge.\nEither one must manually build it or ask for a copy of it from a Confluent representative.\n\n## Install Archive\n\nInstalling from the archive is a manual process and is only supported on unix based systems.\n\nOnce the archive is acquired you will need a place to unzip it.\nI suggest `/opt` or `/usr/local`.\n\n```shell\ncd /usr/local\nunzip jms-bridge-1.0.0-M1.zip\n```\n\nOnce unzipped you should have a folder named `jms-bridge-<version>` and the content of that folder should look like:\n\n```shell\njms-bridge-1.0.0-M1-SNAPSHOT $> ls\nbin   etc   lib  share\n```\n\nThose directories follow the standard linux conventions for naming.\n\n- `bin` contains executables\n- `etc` contains configuration files\n- `lib` contains libraris and jars useful to external processes\n- `share` contains docs, libraries and jars\n\nUpdate the permissions appropriately\n\n```shell\nchmod -R a=rx,u+w bin/\nchmod -R a=r,u+w etc/ share/\n```\n\n## Manual Start\n\nTo start the JMS-Bridge there is the `jms-bridge-server-start` script that can be called.\nOne argument is required and that is the path to the `jms-bridge.properties` file, a default one can be found in the `etc/jms-bridge/` directory.\n\n```shell\nbin/jms-bridge-server-start etc/jms-bridge/jms-bridge.properties\n```\n\nBy default it will run in the foreground and can be killed with `^C`.\nAlternatively you can start it in the background using the `-daemon` option.\n\n```shell\nbin/jms-bridge-server-start -daemon etc/jms-bridge/jms-bridge.properties\n```\n\nAs a companion to the `jms-bridge-server-start` script there is a `jms-bridge-server-stop` script which can be used to stop the JMS-Bridge.\n\n```shell\nbin/jms-bridge-server-stop\n```\n\n```markdown\n    Default location of runtime files of interest:\n\n     * Log files  -> `./logs`\n     * Data files -> `./data`\n```\n\n## Systemd\n\nIt is possible to run it via systemd but I leave that as an exercise for the reader for now.\n\n## Environment Variables\n\nThe environment variables listed below can be used to change the startup behavior.\n\n### JAVA_HOME\n\nThe path to the Java installation you'd like to use.\n\n### JMS_BRIDGE_CLASSPATH\n\nThe JVM classpath used for executing the JMS-Bridge.\n\nThis is a the basis of the classpath and will be appended to by the start scripts.\n\n### JMS_BRIDGE_DATA_DIR\n\nThe directory in which any data files required for the JMS-Bridge will be written to.\n\nDefault: `./data`\n\n### JMS_BRIDGE_HEAP_OPTS\n\nMemory options for the JMS-Bridge's JVM.\n\n### JMS_BRIDGE_JVM_PERFORMANCE_OPTS\n\nPerformance options for the JVM.\nIncludes GC settings.\n\n### JMS_BRIDGE_OPTS\n\nAdditional JVM options that will be passed to the JVM.\n\n### JMS_BRIDGE_JMX_OPTS\n\nOptions used for setting up the JVM's JMX interface.\n\n### JMS_BRIDGE_LOG4J_OPTS\n\nLogging options, based on [log4j2](https://logging.apache.org/log4j/2.x/manual).\n\nFor example to specify a custom logging configuration file you can set this property to\n\n```shell\nexport JMS_BRIDGE_LOG4J_OPTS=\"-Dlog4j2.configurationFile=file:/path/to/log4j2.xml\"\n```\n\nAlternatively to modify the logging you can edit the `etc/jms-bridge/log4j2.xml` file directly.\n\nIncluded with the install is an example rolling file log4j2 configuration, `log4j2-rolling.xml`.\n\nThe `log4j2-cli.xml` file configures logging for the [jms-bridge CLI](cli) command, you may\nmodify that as needed.\n\n### JMX_PORT\n\nThe port on which the JMX interface will be available on.\n\n### LOG_DIR\n\nSets the path to the directory in which log files will be written.\n\nDefault: `./logs`\n\n###\n"},{"url":"/docs/get-started/introduction","title":"Introduction","description":"Learn about the JMS Bridge","section":"Get Started","body":"\nConnect legacy JMS based applications to the Confluent Platform without major modifications.\n\n![Overview Diagram](/overview-diagram.png)\n\n## Overview\n\nThe JMS-Bridge is a component that can be used to facilitate quicker migration from legacy JMS based systems to ones built around the Confluent Platform. It is quite common for enterprise systems to use JMS as a means of integrating external applications to a central system. These applications are usually not maintained by the system owners but by external teams which may not share the same goals or priorities of the system team. This creates a problem when the system team wants to migrate away from their legacy JMS vendor to the Confluent Platform since it would require updating all of those external clients.\n\nEasing this transition is the goal of the JMS-Bridge. By providing a fully compliant JMS 2.0 implementation of the client jars and a server side component it can accommodate the existing patterns of those external JMS applications. With tight integration to the Confluent Platform all JMS originated topic data will be available in Kafka and all Kafka topic data will be available in JMS topics. Since the JMS-Bridge is built on top of the Confluent Platform, using it as it's storage mechanism, it does not require additional disk space or SAN provisioning, if you are monitoring Kafka you are monitoring the JMS-Bridge.\n\n## Features\n\n- Full JMS 2.0 compliance\n- All data stored in Kafka\n- Full integration of topic data between Kafka and JMS-Bridge\n  - Publish from JMS, Consumer from Kafka\n  - Publish from Kafka, Consume from JMS\n\n## Benefits\n\n- Transition from JMS to the Confluent Platform with minor updates to existing JMS applications\n  - client jar update\n- Quickly start innovating using Kafka and the Confluent Platform\n  \\*Allow ample time to either migrate legacy JMS applications or allow them to naturally fade away\n"},{"url":"/docs/get-started/quick-start","title":"Quick Start","description":"Learn how to get started with the JMS Bridge","section":"Get Started","body":"\nAssuming you have <a href=\"https://kafka.apache.org/quickstart\" target=\"_blank\">kafka</a> avaliable at `localhost:9092` and it is not secured (no TLS or ACLs).\n\n## Basic JMS Operations\n\n1. acquire a release archive\n1. unzip the archive into a new directory\n1. change directory to the newly unzipped one\n1. set JAVA_HOME to a java 1.8 JDK installation\n1. make the `bin/` files executable\n1. start the server as a daemon, `jms-bridge-server-start -daemon etc/jms-bridge/quick-start-basic-jms.conf`\n1. open up a new shell in the current directory\n1. use the `jms-bridge` command to start a consumer\n1. from the new shell use the `jms-bridge` command to start publishing messages\n1. once satisfied close out the consumer and producer\n1. shutdown the server by executing the `jms-bridge-server-stop` script\n\n### By Command\n\n```shell\nmkdir jms-bridge-qs\ncd jms-bridge-qs\ncp ~/Downloads/jms-bridge-*.zip ./\nunzip jms-bridge-*\nexport JAVA_HOME=<java-1.8-install-dir>\nchmod -R a=rx,o+w bin/\nbin/jms-bridge-server-start -daemon etc/jms-bridge/quick-start-basic-jms.conf\nbin/jms-bridge jms receive --url tcp://localhost:61616 --topic quick-start\n```\n\nIn a new shell from the same directory\n\n```shell\nexport JAVA_HOME=<java-1.8-install-dir>\nbin/jms-bridge jms send --url tcp://localhost:61616 --topic quick-start\nmy first message\nmy second message\nquit\n```\n\nIn the previous shell\n\n```shell\nbin/jms-bridge-server-stop\n```\n\n## Kafka JMS Integration\n\nAssuming you have kafka avaliable at `localhost:9092` and it is not secured (no TLS or ACLs).\n\nFor this we'll need to use some of the standard Kafka tooling to manage topics and\nproduce/consume from them.\n\nAssuming `kafka-topics`, `kafka-console-consumer` and `kafka-console-producer` are available.\n\n1. acquire a release archive\n1. unzip the archive into a new directory\n1. change directory to the newly unzipped one\n1. set JAVA_HOME to a java 1.8 JDK installation\n1. make the `bin/` files executable\n1. create a kafka topic called `quick-start`\n1. start the server, `jms-bridge-server-start etc/jms-bridge/quick-start-kafka-integration.conf`\n1. open up 4 new shells from the current directory\n1. in the first shell use the `jms-bridge jms receive` command to start a consumer consuming from the `kafka.quick-start` topic\n1. in the second shell start a `kafka-console-consumer` consuming from the `quick-start` topic\n1. in the third shell use the `jms-bridge jms send` command to start publishing messages to the `kafka.quick-start` topic\n1. now from the third shell publish some messages, you should see them showing up in the second shell\n1. in the fourth shell start a `kafka-console-producer` publishing to the `quick-start` topic\n1. from the fourth shell publish some messages, they should show up in the first shell\n1. repeat consuming/producing as much as desired then `control-c` each process and close shells 1, 2, and 4\n1. finally shutdown the server using `control-c` in the original shell (may need to do it twice)\n\n### By Command\n\nIn original shell\n\n```shell script\nmkdir jms-bridge-qs\ncd jms-bridge-qs\ncp ~/Downloads/jms-bridge-*.zip ./\nunzip jms-bridge-*\nexport JAVA_HOME=<java-1.8-install-dir>\nchmod -R a=rx,o+w bin/\ncd jms-bridge-*\nkafka-topics --bootstrap-server localhost:9092 --create --topic quick-start --partitions 3 --replication-factor 1\nbin/jms-bridge-server-start etc/jms-bridge/quick-start-kafka-integration.conf\n```\n\nOpen up 4 new shells from the same directory as the original.\n\nIn shell 1\n\n```shell script\nbin/jms-bridge jms receive --topic kafka.quick-start\n```\n\nIn shell 2\n\n```shell script\nkafka-console-consumer --bootstrap-server localhost:9092 --topic quick-start\n```\n\nIn shell 3\n\n```shell script\nbin/jms-bridge jms send --topic kafka.quick-start\nHello Kafka\n```\n\nObserve in shell 2 that the \"Hello Kafka\" message appears.\n\nIn shell 4\n\n```shell script\nkafka-console-producer --broker-list localhost:9092 --topic quick-start\nHello JMS\n```\n\nObserve in shell 1 that the \"Hello JMS\" message appears.\n\nContinue publishing messages from shell 3 and 4 until you are happy.\n\nClose shells 1, 2, 3, and 4.\n\nIn the original shell send the TERM signal to the JMS-Bridge by using `control-c`.\n\n## Request / Reply Pattern\n\nIn JMS there two different messaging style supported, publish-subscribe (pubsub) and point-to-point (ptp).\nThis differs from Kafka which only supports the pubsub model.\nSince the JMS Bridge resides in both worlds it can be used to facilitate a ptp like interaction between JMS clients and Kafka clients.\n\nIn this example a JMS client will be performing a synchronous request expecting a reply while the Kafka client will be aysnchronously responding to it.\nFrom the JMS client's point of view nothing is unusual since it already supports the ptp model.\nThe Kafka client, on the other hand, will need to do a little extra work to tie the request to the response.\n\nThis example is done in Java and will require the reader to know enough about java development to finish the code, compile it and then execute it.\n\nHere's an example main method for the JMS client:\n\n```java\n    try (\n        //acquire a JMS Session\n        Session session = amqServer.getConnection().createSession(false, Session.AUTO_ACKNOWLEDGE)\n    ) {\n\n      // The JMS topic connected to the Kafka topic that our Kafka client will be responding from\n      Topic requestAmqTopic = session.createTopic(\"kafka.quick-start-request\");\n\n      TopicSession topicSession = (TopicSession) session;\n      TopicRequestor requestor = new TopicRequestor(topicSession, requestAmqTopic);\n\n      try {\n        String request = \"Hello, what's your name?\";\n        TextMessage tmsg = session.createTextMessage(request);\n        System.out.println(\"Request: \" + request);\n        Message response = requestor.request(tmsg);\n        System.out.println(\"Response: \" + response.getBody(String.class));\n      } catch (RuntimeException e) {\n        throw e;\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n\n      System.out.println(\"jms disconnected.\");\n    }\n  }\n```\n\nHere for the Kafka client:\n\n```java\n      try (\n          KafkaProducer<byte[], String> kproducer = new KafkaProducer<>(\n             kprops, new ByteArraySerializer(), new StringSerializer());\n          KafkaConsumer<byte[], String> kconsumer = new KafkaConsumer<>(\n             kprops, new ByteArrayDeserializer(), new StringDeserializer());\n      ) {\n\n        kconsumer.subscribe(Collections.singleton(\"quick-start-request\"));\n\n        while (true) {\n          ConsumerRecords<byte[], String> pollRecords = kconsumer.poll(Duration.ofMillis(100L));\n          if (pollRecords != null) {\n            pollRecords.forEach(request -> {\n\n              //Extract the JMSReployTo header value, should refer to a temporary topic\n              Header replyTo = request.headers().lastHeader(\"jms.JMSReplyTo\");\n              final byte[] destination = replyTo != null\n                  ? replyTo.value()\n                  : null;\n\n              String responseValue = \"Hi, my name is Kafka\";\n              System.out.println(\" Response: \" + responseValue);\n\n              ProducerRecord<byte[], String> response = new ProducerRecord(\n                \"quick-start-response\", request.key(), responseValue);\n\n              if (destination != null) {\n                //set the destination to that temporary topic from the request header\n                response.headers().add(\"jms.JMSDestination\", destination);\n              }\n\n              //synchronous publish for example only, not recommended, use async version with callback instead\n              kproducer.send(response).get();\n            });\n          }\n        }\n      }\n```\n\nFor the example to work some preparatory tasks need to be completed.\n\n1. Create the `quick-start-request` and `quick-start-response` topics in Kafka.\n2. Start the JMS Bridge using the `etc/jms-bridge/quick-start-kafka-request-reply.conf` configuration with the correct `bootstrap.servers`.\n"},{"url":"/docs/guides/clients","title":"Client Integration","description":"Learn how to integrate the JMS Bridge with your applications","section":"Guides","body":"\n## Jar Installation\n\nThe client jar can be found in the release archive, it is compatible with Java 1.8 and newer.\nIn the `lib/jms-bridge/client/` directory you'll find a jar file named `jms-bridge-client-all-<version>.jar`, this contains the client.\nTo use the client you must add it to your applications classpath.\n\n> Summary\n>\n> - add `<release>/lib/jms-bridge/client/jms-bridge-client-all-<version>.jar` to your applications classpath\n\n## Replacing an Existing JMS Implementation\n\nTo replace an existing JMS implementation within an application you must:\n\n1.  Remove the current implementation jar from the applications classpath\n1.  Add the above client-jar to the classpath\n1.  Restart the application\n\nThis works as long as the application did not depend on any vendor specific extensions to the JMS specification.\n\n## Using Maven Dependency\n\nYou can also get the client jar via a maven dependency.\nSince the JMS-Bridge uses an embedded version of the popular ActiveMQ Artemis Broker you can use it as an equivelant replacement of the jms-bridge client jar.\nIn fact, they are the same thing.\nJust make sure to get the right version, it should match the version found in the name of the jms-bridge client jar.\n\n_maven_\n\n```xml\n<dependency>\n    <groupId>org.apache.activemq</groupId>\n    <artifactId>artemis-jms-client-all</artifactId>\n    <version>2.13.0</version>\n</dependency>\n```\n\n_gradle_\n\n```groovy\ncompile group: 'org.apache.activemq', name: 'artemis-jms-client-all', version: '2.13.0'\n```\n\n## Client Usage\n\nSee the artemis documentation for many examples of using the JMS client jar.\n\nhttps://activemq.apache.org/components/artemis/documentation/latest/using-jms.html\n"},{"url":"/docs/guides/installation","title":"Installation Guide","description":"Learn how to install the JMS Bridge","section":"Guides","body":"\nThis guide provides instructions for installing the JMS Bridge, including The JMS Bridge, and the Confluent Platform.\n\nFor non-production enviroments (such as testing and proof-of-concept use cases), see The [quickstart guide](http://wwww.google.com) for limited installation procedures.\n\nThis guide includes the following sections:\n* [Before You Install](#before-you-install)\n* [Installing the JMS Bridge](#installing-the-jms-bridge)\n* [Uninstalling the JMS Bridge](uninstall)\n\n\n## System Requirements\n\nBefore you install the JMS Bridge:\n\n- Review the JMS Bridge Requirements and supported OS Versions.\n- Review the JMS Bridge Release Notes.\n\n#### Hardware\n\nThe following machine recommendations are for installing individual Confluent Platform components:\n\n| Component         | Storage | Memory | CPU |\n| ----------------- | :-----: | -----: | --- |\n| JMS Master Broker |         |        |     |\n| JMS Slave         |         |        |     |\n\n#### Operating Systems\n\nThe JMS Bridge required a linux distribution in order to function. Windows is not currently supported for the JMS Bridge.\n\n| Operating System | Early Release | 1.0 | 2.0 |\n| ---------------- | :-----------: | --: | --- |\n| RHEL/CentOS 7.x  |      Yes      | Yes | Yes |\n\n- macOS 10.13 and later is supported for testing and development purposes only.\n\n## Before you Install\n\nBefore you install the JMS Bridge:\n\n- Review the JMS Bridge Requirements and supported OS Versions.\n- Review the JMS Bridge Release Notes.\n\n### Active Confluent Cluster\n\nPlease refer to confluent platform documentation [Active Active Cluster](https://docs.confluent.io/platform/current/multi-dc-deployments/multi-region-architectures.html#:~:text=A%202%2B%2Dcluster%20active,failover%20to%20the%20other%20cluster.)\n\n### JDK\n\nThe JMS Bridge Requires the use of a supported JDK to operate. Current supported JDK Versions include:\n\n| Component  |    Version     |\n| ---------- | :------------: |\n| Oracle JDK | 1.8 or greater |\n\n#### Installing customer provided JDK\n\n> Note: A Java optimization called compressed oops (ordinary object pointers) enables a 64-bit JVM to address heap sizes up to about 32 GB using 4-byte pointers. For larger heap sizes, 8-byte pointers are required. This means that a heap size slightly less than 32 GB can hold more objects than a heap size slightly more than 32 GB.\n\nThe Oracle JDK installer is available both as an RPM-based installer for RPM-based systems, and as a .tar.gz file. These instructions are for the .tar.gz file.\n\n1. Download the .tar.gz file for one of the 64-bit supported versions of the Oracle JDK from [Java SE 8 Downloads](https://www.oracle.com/java/technologies/javase/javase8-archive-downloads.html). (This link is correct at the time of writing, but can change.)\n\n   > Note:\n   >\n   > If you want to download the JDK directly using a utility such as wget, you must accept the Oracle license by configuring headers, which are updated frequently. Blog posts and Q&A sites can be a good source of information on how to download a particular JDK version using wget.\n\n2. Extract the JDK to `/usr/java/jdk-version`. For Example:\n   ```shell\n   $ tar xvfz /path/to/jdk-8u<update_version>-linux-x64.tar.gz -C /usr/java/\n   ```\n3. Set JAVA_HOME\n\n   ```shell\n   $ touch ~/.profile\n   $ vi ~/.profile\n   JAVA_HOME=/usr/java/jdk1.8.0_261.jdk/Contents/Home\n       export JAVA_HOME;\n       $JAVA_HOME/bin/java -version\n   ```\n\n### Disable SELinux\n\nSecurity-Enhanced Linux (SELinux) allows you to set access control through policies. If you are having trouble deploying the JMS Bridge with your policies, set SELinux in permissive mode on each host before you deploy the JMS Bridge on your node.\n\nTo set the SELinux mode, perform the following steps on each host.\n\n1. Check the SELinux state:\n   ```shell\n   $ getenforce\n   ```\n2. If the output is either 'Permissive' or 'Disabled', you can skip this task and continue on to Disabling the Firewall. If the output is enforcing, continue to the next step.\n3. Open the '/etc/selinux/config' file (in some systems, the '/etc/sysconfig/selinux' file).\n4. Change the line 'SELINUX=enforcing' to 'SELINUX=permissive'.\n5. Save and close the file.\n6. Restart your system or run the following command to disable SELinux immediately:\n   ```shell\n   $ setenforce 0\n   ```\n\n### Disable SELinux\n\nMost Linux platforms supported by the JMS Bridge include a feature transparent hugepages, which interacts could impact how the JMS bridges embedded ActiveMQ Artemis server stores data in memory.\n\nTo disable Transparent Hugepages, perform the following steps:\n\n1. To disable transparent hugepages on reboot, add the following commands to the /etc/rc.d/rc.local file on the host:\n   ```shell\n   echo never > /sys/kernel/mm/transparent_hugepage/enabled\n   echo never > /sys/kernel/mm/transparent_hugepage/defrag\n   ```\n\n### Required Ports\n\n### **_Optional_** System Service Account\n\nCreating an ‘JMS’ User and Group\n`shell\n    $ sudo groupadd artemis\n    $ sudo useradd -s /bin/false -g artemis -d /opt/artemis artemis\n    `\n\n### **_Optional_** System Service Account\n\nCreating an ‘JMS’ User and Group\n`shell\n    $ sudo groupadd artemis\n    $ sudo useradd -s /bin/false -g artemis -d /opt/artemis artemis\n    `\n\n### **_Optional_** Configure Network Names\n\nConfigure each host in the cluster as follows to ensure that all members can communicate with each other:\n\n1. Set the hostname to a unique name (not localhost).\n   ```shell\n   $ sudo hostnamectl set-hostname foo-1.example.com\n   ```\n2. Edit /etc/hosts with the IP address and fully qualified domain name (FQDN) of each host in the cluster. You can add the unqualified name as well.\n   ```shell\n   1.1.1.1  foo-1.example.com  foo-1\n   2.2.2.2  foo-2.example.com  foo-2\n   3.3.3.3  foo-3.example.com  foo-3\n   4.4.4.4  foo-4.example.com  foo-4\n   ```\n3. Edit '/etc/sysconfig/network' with the FQDN of this host only:\n   ```shell\n   HOSTNAME=foo-1.example.com\n   ```\n4. Verify that each host consistently identifies to the network:\n\n   1. Run 'uname -a' and check that the hostname matches the output of the hostname command.\n      ```shell\n      HOSTNAME=foo-1.example.com\n      ```\n   2. Run /sbin/ifconfig and note the value of inet addr in the eth0 (or bond0) entry, for example:\n\n      ```shell\n      eth0      Link encap:Ethernet  HWaddr 00:0C:29:A4:E8:97\n                inet addr:172.29.82.176  Bcast:172.29.87.255  Mask:255.255.248.0\n      ...\n      ```\n\n   3. Run 'host -v -t A $(hostname)' and verify that the output matches the hostname command.\n      The IP address should be the same as reported by ifconfig for eth0 (or bond0):\n      ```shell\n      Trying \"foo-1.example.com\"\n      ...\n      ;; ANSWER SECTION:\n      foo-1.example.com. 60 IN\tA\t172.29.82.176\n      ```\n\n## Installing the JMS Bridge\n\n### Obtaining a copy of the JMS Bridge\n\nTo obtain a copy of the JMS-Bridge, please contact your Account Executive or Confluent Support.\n\n### Unzip the JMS Bridge Archive\n\n        ```shell\n        cd /usr/local\n        unzip jms-bridge-1.0.0-M1.zip\n         ```\n\n#### Place Archive in your organizations preffered deployment directory.\n\n`The recommended location for instation is '/opt' or '/usr/local' depending on the use of a service user account for installation.`\n\n```shell\ncd /usr/local\nunzip jms-bridge-1.0.0-M1.zip\n```\n\n#### Update the broker directory permissions\n\nIn order to execute, the JMS bridge directory permissions must be modified. It is highly recommended to never use '777' when deploying in a production environment.\n\n```shell\nchmod -R a=rx,u+w bin/\nchmod -R a=r,u+w etc/ share/\n```\n\n### The JMS bridge is now ready to\n\n#### Starting\n\nTo start the JMS-Bridge there is the `jms-bridge-server-start` script that can be called.\nOne argument is required and that is the path to the etc/jms-bridge.properties file, this is a [template](https://github.com/confluentinc/csid-jms-bridge/tree/master/config/quick-start-kafka-request-reply.properties) directory.\n```shell\nbin/jms-bridge-server-start etc/jms-bridge/jms-bridge.properties\n```\n\nBy default it will run in the foreground and can be killed with `^C`.\nAlternatively you can start it in the background using the `-daemon` option.\n\n```shell\nbin/jms-bridge-server-start -daemon etc/jms-bridge/jms-bridge.properties\n```\n\nAs a companion to the `jms-bridge-server-start` script there is a `jms-bridge-server-stop` script which can be used to stop the JMS-Bridge.\n\n```shell\nbin/jms-bridge-server-stop\n```\n\n```markdown\n    Default location of runtime files of interest:\n\n     * Log files  -> `./logs`\n     * Data files -> `./data`\n```\n\n##### Systemd\n\nIt is possible to run it via systemd but I leave that as an exercise for the reader for now.\n\n## Configuration Options\n\nAll configuration for the JMS Bridge is done via a properties file which is supplied to the `jms-bridge-server-start` script.\nAn example configuration can be found in [etc/jms-bridge/quick-start-kafka-request-reply.properties](https://github.com/confluentinc/csid-jms-bridge/tree/master/config/quick-start-kafka-request-reply.properties) \n\n### JMSBridge Configuration\n\nSince the underlying JMS engine is a customized embedded Apache ActiveMQ Artemis broker one can configure that directly.\nTo do so requires editing the `broker.xml` file found in the `etc/jms-bridge` directory.\nThe `broker.xml` file must be located next to the configured `jms-bridge.properties` file or it will not be found.\n\nA default `broker.xml` is supplied with the installation.\nFeel free to update it as desired.\nThe reference for that file can be found on the Artemis documentation site:\nhttps://activemq.apache.org/components/artemis/documentation/latest/configuration-index.html\n\n#### Configuration Caveats\n\n#### Clusters\n\nJMS-Bridge clusters allow groups of JMS-bridge servers to be grouped together in order to share message processing load. Each active node in the cluster is an active JMS-Bridge server which manages its own messages and handles its own connections.\n\nThe cluster is formed by each node declaring cluster connections to other nodes in the core configuration file broker.xml .\nWhen a node forms a cluster connection to another node, internally it creates a core bridge (as described in Core Bridges) connection between it and the other node, this is done transparently behind the scenes - you don't have to declare an explicit bridge for each node.\n\nClustering for the JMS-Bridge was tested by explicitly setting host connections. This can only be done using a static list of connectors and is configured as follows:\n\n1. Define 'cluster-connections':\n   ```xml\n   <cluster-connection name=\"my-cluster\">\n       <address>jms</address>\n       <connector-ref>netty-connector</connector-ref>\n       <retry-interval>500</retry-interval>\n       <use-duplicate-detection>true</use-duplicate-detection>\n       <message-load-balancing>STRICT</message-load-balancing>\n       <max-hops>1</max-hops>\n       <static-connectors allow-direct-connections-only=\"true\">\n       <connector-ref>server1-connector</connector-ref>\n       </static-connectors>\n   </cluster-connection>\n   ```\n2. Add the new connector defined in the 'cluster-connection' node to the connectors xml node.\n   ```xml\n   <connectors>\n     <!-- Default Connector.  Returned to clients during broadcast and distributed around cluster.  See broadcast and discovery-groups -->\n     <connector name=\"activemq\">\n       tcp://${activemq.remoting.default.host:localhost}:${activemq.remoting.default.port:61616}\n     </connector>\n     <connector name=\"server1-connector\">tcp://hostname:61616</connector>\n   </connectors>\n   ```\n\n> Conector names in both the cluster-connections and the connectors node, must match.\n\n#### High Availability and Failover\n\nThe JMS-Bridge allows servers to be linked together as live - backup groups where each live server can have one or more backup servers. A backup server is owned by only one live server. Backup servers are not operational until failover occurs, however 1 chosen backup, which will be in passive mode, announces its status and waits to take over the live servers work\nBefore failover, only the live server is serving the Apache ActiveMQ Artemis clients while the backup servers remain passive or awaiting to become a backup server. When a live server crashes or is brought down in the correct mode, the backup server currently in passive mode will become live and another backup server will become passive. If a live server restarts after a failover then it will have priority and be the next server to become live when the current live server goes down, if the current live server is configured to allow automatic failback then it will detect the live server coming back up and automatically stop.\n\nDue to the addition of Kafka as a storage mechanism for the JMS Bridge, only one option is currently supported for high availability in contrast to traditional ActiveMQ.\n\nTo configure High Availability, perform the following steps:\n\n1. Cluster two or odes together using a telopolgy of the organizations choise. Please note that any topology that uses the redistribution of journals will ot be supported.\n2. On the 'master' node, please set the following configuration. the configurations 'failover-on-shutdown'\n   ```xml\n    <ha-policy>\n      <shared-store>\n        <master>\n          <failover-on-shutdown>true</failover-on-shutdown>\n        </master>\n      </shared-store>\n    </ha-policy>\n    ```\n   `Be aware that if you restart a live server while after failover has occurred then check-for-live-server must be set to true . If not the live server will restart and server the same messages that the backup has already handled causing duplicates.` >\n3. On the 'slave' node, define the preferred state of the slave JMS-Bridge Server.\n    ```xml\n    <ha-policy>\n      <shared-store>\n        <slave>\n          <allow-failback>true</allow-failback>\n        </slave>\n      </shared-store>\n    </ha-policy>\n    ```\n"},{"url":"/docs/guides/uninstall","title":"Uninstalling The JMS Bridge","description":"Learn how to uninstall the JMS Bridge","section":"Guides","body":"\n## Linux Terminal\n\nTo remove the JMS-Bridge itself from Linux execute on terminal:\n\n1. Stop installed broker running via\n\n   ```shell\n   kill -9 <pid>\n   ```\n\n2. `Optional:` Remove / Delete the JMS Broker Directory\n\n   ```shell\n   rm -rf /jms-bridge-server-0.1.0-SNAPSHOT/*\n   ```\n"},{"url":"/docs/guides/upgrade","title":"Upgrading the JMS Bridge","description":"Learn how to upgrade the JMS Bridge","section":"Guides","body":"\n## General Upgrade Procedure\n\nDepending on the version of the JMS Bridge that is being upgraded, steps may differ. Please consult the release notes from each version to ensure caveats do not apply.\n\nTo upgrade this of the JMS bridge please follow the following steps:\n\n1. Navigate to the etc folder of the broker instance that's being upgraded\n2. Open broker.xml and jms-bridge.properties files. It contains a property which is relevant for the upgrade:\n\n   ```shell\n   <env name=\"ARTEMIS_HOME\" value=\"/path/to/apache-artemis-version\"/>\n   ```\n\nThe ARTEMIS_HOME property is used to link the instance with the home. In most cases the instance can be upgraded to a newer version simply by changing the value of this property to the location of the new broker home. Please refer to the aforementioned versions document for additional upgrade steps (if required).\n\nIn most cases the instance can be upgraded to a newer version simply by changing the value of this property to the location of the new broker home. Please refer to the aforementioned versions document for additional upgrade steps (if required).\n"},{"url":"/docs/legal/notice","title":"Legal Notice","description":"Legal Notice","section":"Legal Notice","body":"\nSubject to the terms of this Exhibit and the applicable Order, Confluent grants to Customer a limited, perpetual, royalty free, non-exclusive, non-sublicensable, non-transferable license to install, use, and modify Confluent’s CP e2e JMS Bridge accelerator software (“Accelerator Software”), solely for Customer’s internal business operations. Customer shall not, and shall not permit or encourage any third party to: (a) use the Accelerator Software for third-party training, software-as-a-service, time-sharing or service bureau use or any other external business purpose, (b) disassemble, decompile or reverse engineer any portions of the Accelerator Software that are not provided in source code format, or otherwise attempt to gain access to the source code to such Accelerator Software. The foregoing restriction is inapplicable to the extent prohibited by applicable law. Customer acknowledges that Confluent retains all proprietary rights, title and interest, including all intellectual property rights, in and to the Accelerator Software and any changes and other modifications thereto, and as between the parties all such rights shall vest in Confluent. Confluent reserves all rights not expressly granted herein. No rights are granted by implication. The Accelerator Software will not be supported by Confluent and no updates, upgrade, bug fixes, patches, new version will be provided. The Accelerator Software will be delivered only through an electronic transfer. Confluent provides the Accelerator Software free-of-charge and assumes no warranty or any kind of responsibility for any fit of purpose, specifications, requirements or compatibility requested or intended by Customer. Customer acknowledges that the Accelerator Software was properly reviewed before being installed and used and is provided by Confluent as-is.\n\n**Last updated August 2020**\n"},{"url":"/docs/sequence-diagrams/sq_jms_prod_kafka_cons","title":"JMS Producer to Kafka Consumer","description":"Sequence Diagram to show data flow","section":"Diagrams","body":"\nJMS Producer to Kafka Consumer\n\n```mermaid\nsequenceDiagram\n    participant JMS Consumer\n    participant JMS Queue\n    participant JMS Publisher\n    participant JMS Topic 'orders'\n\n    participant Divert\n    participant Kafka Exchange Queue\n\n    participant Kafka Ingress Process\n    participant Kafka Egress Process\n    participant Orders\n\n    participant Kafka Consumer\n    participant Kafka Producer\n\n    JMS Publisher->>+JMS Topic 'orders': Publishes data to topic\n    JMS Topic 'orders'->>+Divert : \n\n    Divert ->>+Kafka Exchange Queue: \n    Kafka Exchange Queue->>+Kafka Ingress Process: \n    Kafka Ingress Process->>Orders: \n    Note right of Orders: Confluent Platform\n    Note left of Orders: All JMS properties are converted to Kafka headers <br/>with a prefix of ‘jms’. Origin header is also added\n    Orders->>+Kafka Consumer: \n    Note right of Divert: Exclusive divert using a selector prevents <br/>JMS queues from getting dupes and data cycles.\n\n\n\n```\n"},{"url":"/docs/sequence-diagrams/sq_jms_prod_kafka_cons_error","title":"JMS Producer to Kafka Consumer - Error","description":"Sequence Diagram to show error flow","section":"Diagrams","body":"\nJMS Producer to Kafka Consumer - Error\n\n```mermaid\nsequenceDiagram\n    participant JMS Consumer\n    participant JMS Queue\n    participant JMS Publisher\n    participant JMS Topic 'orders'\n\n    participant Divert\n    participant Kafka Exchange Queue\n\n    participant Kafka Ingress Process\n    participant Kafka Egress Process\n    participant Orders\n\n    participant Kafka Consumer\n    participant Kafka Producer\n    JMS Topic 'orders'->>Kafka Exchange Queue: Typical Interaction\n    note over Divert: Errors between these points will go back to the publisher\n    Kafka Exchange Queue->>Kafka Ingress Process: Blah\n    note left of Kafka Ingress Process: Errors between these points will go back to the publisher\n```\n"},{"url":"/docs/sequence-diagrams/sq_kafka_prod_jms_cons","title":"Kafka Producer to JMS Consumer","description":"Sequence Diagram to show data flow","section":"Diagrams","body":"\nKafka Producer to JMS Consumer\n\n```mermaid\nsequenceDiagram\n    participant JMS Consumer\n    participant JMS Queue\n    participant JMS Publisher\n    participant JMS Topic 'orders'\n\n    participant Divert\n    participant Kafka Exchange Queue\n\n    participant Kafka Ingress Process\n    participant Kafka Egress Process\n    participant Orders\n\n    participant Kafka Consumer\n    participant Kafka Producer\n\n    Kafka Producer->>Orders: \n    Orders->>Kafka Egress Process: \n    note over Kafka Egress Process: Message is tagged with an <br/> origin header to prevent data cycles.\n\n    Kafka Egress Process->>JMS Topic 'orders': \n\n    JMS Topic 'orders'->>JMS Queue: \n\n    JMS Queue->>JMS Consumer: \n\n    Note over JMS Queue: If no consumer queue <br/> is bound to the topic, then <br/> the message is unrouted <br/> and not persisted.\n\n\n    \n```\n"},{"url":"/docs/sequence-diagrams/sq_kafka_prod_jms_cons_error","title":"Kafka Producer to JMS Consumer - Error","description":"Sequence Diagram to show error flow","section":"Diagrams","body":"\nKafka Producer to JMS Consumer - Error\n\n```mermaid\nsequenceDiagram\n    participant JMS Consumer\n    participant JMS Queue\n    participant JMS Publisher\n    participant JMS Topic 'orders'\n\n    participant Divert\n    participant Kafka Exchange Queue\n\n    participant Kafka Ingress Process\n    participant Kafka Egress Process\n    participant Orders\n\n    participant Kafka Consumer\n    participant Kafka Producer\n\n    Kafka Egress Process->JMS Queue: \n    Note over Divert: Errors between these points will go back to Kafka\n```\n"}]